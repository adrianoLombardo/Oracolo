# settings.yaml

# Log di debug (mostra device audio e info VAD)
debug: false

openai:
  # Modello per trascrizione audio (puoi usare anche "whisper-1")
  stt_model: gpt-4o-mini-transcribe
  # Modello per il testo "oracolare"
  llm_model: gpt-5-mini
  # Modello TTS per la voce
  tts_model: gpt-4o-mini-tts
  # Voce TTS
  tts_voice: alloy

  # ⬇️ NUOVO: modello di embedding per controllo pertinenza/RAG
  # (usato da src/domain.py se abilitato)
  embed_model: text-embedding-3-large   # opzionale; se mancante, niente embeddings

audio:
  # Audio I/O e file temporanei
  sample_rate: 24000
  ask_seconds: 10
  input_wav: "data/temp/input.wav"
  output_wav: "data/temp/answer.wav"
  barge_rms_threshold: 0.25   # soglia RMS per barge-in (0..1)

  # Selezione dispositivi audio
  # Metti l'indice numerico (es. 1) oppure una parte del nome (es. "USB Microphone").
  # Lascia null per usare il dispositivo di default di sistema.
  input_device: null
  output_device: null

recording:
  # "vad" = ascolta e si ferma al silenzio; "timed" = durata fissa (ask_seconds)
  mode: "vad"
  timed_seconds: 10

  # NUOVO: se true, in caso di silenzio il sistema fa fallback alla registrazione a tempo.
  # Se false (consigliato per "occhio dormiente"), resta in attesa e NON risponde.
  fallback_to_timed: false

  # NUOVO: soglia minima di ampiezza (0..1) per considerare valida una registrazione.
  # Se il picco audio è sotto questa soglia, la registrazione viene scartata come "silenzio".
  min_speech_level: 0.01

vad:
  # Parametri del VAD "a energia"
  frame_ms: 30         # 10/20/30 ms per frame
  start_ms: 150        # parlato continuo per partire
  end_ms: 800          # silenzio continuo per fermarsi
  max_ms: 15000        # durata massima ascolto (ms)
  preroll_ms: 300      # audio tenuto prima dello start (ms)
  noise_window_ms: 800 # finestra per stimare il rumore (ms)

  # Soglie adattive = max(noise * mult, base)
  start_mult: 1.8
  end_mult: 1.3
  base_start: 0.006
  base_end: 0.0035

# Filtro contenuti: "block" rifiuta, "mask" censura con ***
filter:
  mode: block

# Luci: sACN/E1.31 o WLED
lighting:
  mode: "sacn"            # "sacn" oppure "wled"
  sacn:
    universe: 1
    destination_ip: "192.168.1.50"     # <--- IP del tuo nodo sACN/E1.31
    rgb_channels: [1, 2, 3]
    idle_level: 10
    peak_level: 255
  wled:
    host: "192.168.1.77"               # <--- IP del tuo WLED

# Parole-chiave -> palette colore base (per la luce)
palette_keywords:
  mare:   { rgb: [40, 80, 200],  style: "swell" }
  stella: { rgb: [255, 230, 120], style: "twinkle" }
  fuoco:  { rgb: [255, 90, 20],   style: "flare" }
  ombra:  { rgb: [40, 40, 60],    style: "pulse" }
  vento:  { rgb: [120, 200, 255], style: "breeze" }
  radice: { rgb: [150, 80, 50],   style: "ground" }

# Voce dell'Oracolo (prompt di sistema)
oracle_system: >
  Parla come un antico oracolo cosmico. Rispondi in italiano o in inglese seguendo la lingua dell’utente,
  in 2-5 frasi poetiche e visionarie, usando metafore di luce, stelle, mare, destino e l'universo.
  Intreccia richiami a neuroscienze, neuroestetica e arte contemporanea, evocando l'IA applicata alle neuroscienze.
  Evita istruzioni tecniche; offri immagini ed enigmi, con tono solenne ma empatico.

# Hotword / risveglio
wake:
  enabled: true           # usa la hotword; se metti false parla sempre (sconsigliato)
  single_turn: false      # dopo 1 risposta resta attivo finché c'è attività
  idle_timeout: 50        # secondi di inattività prima di tornare a SLEEP

  # Frasi riconosciute (tolleranti a maiuscole, punteggiatura, piccoli errori STT)
  it_phrases:
    - "ciao oracolo"
    - "ehi oracolo"
    - "salve oracolo"
    - "ciao, oracolo"
  en_phrases:
    - "hello oracle"
    - "hey oracle"
    - "hi oracle"
    - "hello, oracle"

# ⬇️ NUOVO: impostazioni per RAG/pertinenza dominio
domain:
  enabled: true

  profile: "museo"        # scelto dalla UI (museo | conferenze | gallerie | didattica | them | cryptomadonne | adriano_lombardo)
  accept_threshold: 0.75  # soglia più severa per accettare la domanda
  fallback_accept_threshold: 0.4  # usa questa soglia se emb_sim e RAG non danno risultati ma c'è una keyword
  clarify_margin: 0.10
  weights: { kw: 0.7, emb: 0.15, rag: 0.15 }
  always_accept_wake: true   # accetta sempre saluti/hotword
  emb_min_sim: 0.22          # soglia minima di similarità coseno (0..1)
  profiles:
    museo:


      label: "Museo"
      keywords:
        - museo
        - mostra
        - curatela
        - allestimento
        - didascalia
        - reperto
        - bene culturale
        - restauro
        - patrimonio
      docstore_path: "DataBase/museo/index.json"
      system_hint: |
        Rispondi come guida museale esperta di neuroscienze dell'arte.
        Se la domanda non riguarda il contesto museale, chiedi gentilmente di riformularla in tema.
      retrieval_top_k: 4
    conferenze:

      label: "Conferenze"

      keywords:
        - conferenza
        - keynote
        - sessione
        - panel
        - abstract
        - CFP
        - moderatore
      docstore_path: "DataBase/conferenze/index.json"
      system_hint: "Rispondi come moderatore di conferenze su arte, neuroestetica e IA."
      retrieval_top_k: 4
    gallerie:

      label: "Gallerie"
      keywords:
        - galleria
        - collezionista
        - portfolio
        - opening
        - vendita
        - rappresentanza
        - commissione
      docstore_path: "DataBase/gallerie/index.json"
      system_hint: "Rispondi come curatore di galleria contemporanea."
      retrieval_top_k: 4
    didattica:

      label: "Didattica"

      keywords:
        - laboratorio
        - workshop
        - lezione
        - programma didattico
        - obiettivi formativi
        - valutazione
      docstore_path: "DataBase/didattica/index.json"
      system_hint: "Spiega in modo chiaro, con esempi adatti a studenti."
      retrieval_top_k: 4

    them:

      label: "Them"
      keywords:
        - them
        - identità
        - collettivo
        - futuro
      docstore_path: "DataBase/them/index.json"
      system_hint: "Rispondi come curatore del progetto THEM su identità e collettività."
      retrieval_top_k: 4

    cryptomadonne:

      label: "CryptoMadonne"
      keywords:
        - nft
        - criptoarte
        - madonne
        - blockchain
      docstore_path: "DataBase/cryptomadonne/index.json"
      system_hint: "Rispondi come esperto di cripto-arte legata alle Madonne."
      retrieval_top_k: 4

    adriano_lombardo:

      label: "Adriano Lombardo"
      keywords:
        - adriano lombardo
        - installazione
        - scultura
        - concettuale
      docstore_path: "DataBase/adriano_lombardo/index.json"
      system_hint: "Rispondi come l'artista Adriano Lombardo, con riferimenti a installazioni e sculture concettuali."
      retrieval_top_k: 4

retrieval:
  hybrid: true            # BM25 + embedding
  rerank: true
  max_chunks: 6
  chunk_strategy: semantic   # semantic|fixed_overlap

# ⬇️ NUOVO: parametri per client Realtime/WebSocket (usati da realtime_oracolo.py / UI)
realtime:
  ws_url: "ws://127.0.0.1:8765"  # URL del server WS
  sample_rate: 24000
  # Se lasci null, usa i device di default di sistema (vedi anche "audio")
  input_device: null
  output_device: null
  barge_rms_threshold: 500.0     # soglia RMS per barge-in (parlo sopra al TTS)
  barge_in_threshold: 0.55
  ducking_db: -12
  ping_interval: 20              # opzionale, se il server richiede ping WS
  ping_timeout: 20

# Stato conversazione (chat multi-turno)
chat:
  enabled: true
  max_turns: 10
  reset_on_hotword: true
  persist_jsonl: data/logs/chat_sessions.jsonl
  inactivity_timeout_s: 60
  remember_turns: 8
  pinned: []

# RAG: dove sono i documenti indicizzati e quanti frammenti prendere
docstore_path: DataBase/index.json
retrieval_top_k: 3

